# ============================================================
# Variational Autoencoder on CelebA-HQ Mask dataset
# ============================================================

# ---- Imports ----
from datasets import load_dataset
from torchvision import transforms
from torch.utils.data import DataLoader
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision.utils import save_image
import os

# ---- Load dataset from HuggingFace ----
ds = load_dataset("eurecom-ds/celeba_hq_mask")

# Define preprocessing
transform = transforms.Compose([
    transforms.Resize((64, 64)),     # resize to manageable resolution
    transforms.ToTensor()            # convert PIL -> tensor in [0,1]
])

# Convert HuggingFace dataset into PyTorch-style samples
def transform_batch(batch):
    imgs = [transform(img) for img in batch["image"]]
    return {"image": imgs}

train_data = ds["train"].with_transform(transform_batch)
train_loader = DataLoader(train_data, batch_size=64, shuffle=True, num_workers=2)

# ---- Define VAE ----
class VAE(nn.Module):
    def __init__(self, img_channels=3, latent_dim=128):
        super(VAE, self).__init__()
        # Encoder: input 3x64x64
        self.enc = nn.Sequential(
            nn.Conv2d(img_channels, 32, 4, 2, 1),  # 32x32x32
            nn.ReLU(),
            nn.Conv2d(32, 64, 4, 2, 1),            # 64x16x16
            nn.ReLU(),
            nn.Conv2d(64, 128, 4, 2, 1),           # 128x8x8
            nn.ReLU(),
            nn.Conv2d(128, 256, 4, 2, 1),          # 256x4x4
            nn.ReLU()
        )
        self.fc_mu = nn.Linear(256*4*4, latent_dim)
        self.fc_logvar = nn.Linear(256*4*4, latent_dim)

        # Decoder
        self.fc_decode = nn.Linear(latent_dim, 256*4*4)
        self.dec = nn.Sequential(
            nn.ConvTranspose2d(256, 128, 4, 2, 1),  # 8x8
            nn.ReLU(),
            nn.ConvTranspose2d(128, 64, 4, 2, 1),   # 16x16
            nn.ReLU(),
            nn.ConvTranspose2d(64, 32, 4, 2, 1),    # 32x32
            nn.ReLU(),
            nn.ConvTranspose2d(32, img_channels, 4, 2, 1),  # 64x64
            nn.Sigmoid()
        )

    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std

    def forward(self, x):
        h = self.enc(x)
        h = h.view(h.size(0), -1)
        mu, logvar = self.fc_mu(h), self.fc_logvar(h)
        z = self.reparameterize(mu, logvar)
        h_dec = self.fc_decode(z).view(-1, 256, 4, 4)
        x_recon = self.dec(h_dec)
        return x_recon, mu, logvar

# ---- Loss function ----
def vae_loss(recon_x, x, mu, logvar):
    recon_loss = F.mse_loss(recon_x, x, reduction="sum")
    kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
    return recon_loss + kl_div

# ---- Training setup ----
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
vae = VAE(img_channels=3, latent_dim=128).to(device)
optimizer = optim.Adam(vae.parameters(), lr=1e-3)

num_epochs = 20
os.makedirs("vae_outputs", exist_ok=True)

# ---- Training loop ----
for epoch in range(num_epochs):
    vae.train()
    total_loss = 0
    for batch in train_loader:
        imgs = batch["image"].to(device)
        optimizer.zero_grad()
        recon_imgs, mu, logvar = vae(imgs)
        loss = vae_loss(recon_imgs, imgs, mu, logvar)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    avg_loss = total_loss / len(train_loader.dataset)
    print(f"Epoch [{epoch+1}/{num_epochs}] Loss: {avg_loss:.4f}")

    # saving reconstruction samples
    if (epoch + 1) % 5 == 0:
        vae.eval()
        with torch.no_grad():
            sample = recon_imgs[:64]
            save_image(sample, f"vae_outputs/reconstruction_epoch_{epoch+1}.png", nrow=8)

# ---- Sampling new images from latent space ----
vae.eval()
with torch.no_grad():
    z = torch.randn(64, 128).to(device)  # random latent samples
    gen = vae.dec(vae.fc_decode(z).view(-1, 256, 4, 4))
    save_image(gen, "vae_outputs/generated_faces.png", nrow=8)

print("âœ… Training complete! Generated images saved in 'vae_outputs/'.")
